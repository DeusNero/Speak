<script>
// --- DEBUG START ---
alert("SYSTEM CHECK: App Loaded v4.0"); 
// If you don't see this popup when you refresh, your JS is broken.
// -------------------

const MOODS={1:'\u{1f622}',2:'\u{1f615}',3:'\u{1f610}',4:'\u{1f642}',5:'\u{1f60a}'};
const STORAGE_KEY='speak_captures';
const SETTINGS_KEY='speak_settings';
const SMILEY_SVG='<svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round"><circle cx="12" cy="12" r="10"/><path d="M8 14s1.5 2 4 2 4-2 4-2"/><line x1="9" y1="9" x2="9.01" y2="9"/><line x1="15" y1="9" x2="15.01" y2="9"/></svg>';

// Initialize Data
let captures = JSON.parse(localStorage.getItem(STORAGE_KEY) || '[]');
let settings = JSON.parse(localStorage.getItem(SETTINGS_KEY) || '{}');
if (!settings.defaultLang) settings.defaultLang = 'en-US'; // Default to English for testing
let currentCapture = { text: '', mood: null, tags: [] };
let isRecording = false;
let recognition = null;
let recordingTimer = null;
let recordingSeconds = 0;

// Speech Recognition Setup
const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
const speakBtn = document.getElementById('speak-btn');
const timerEl = document.getElementById('speak-timer');

// --- DEBUG: CHECK SUPPORT ---
if (!SR) {
    alert("CRITICAL: Speech Recognition NOT supported in this browser.");
} else {
    // alert("Speech Recognition IS supported."); // Uncomment if needed
}

if (!SR) {
    // Fallback for non-supported browsers
    speakBtn.addEventListener('click', () => {
        const t = prompt('Speech recognition not available.\nType your thought:');
        if (t && t.trim()) {
            currentCapture.text = t.trim();
            showPostRecordFlow();
        }
    });
} else {
    try {
        recognition = new SR();
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = settings.defaultLang;

        let finalTranscript = '';
        
        recognition.onstart = () => {
            alert("Mic Started!"); // DEBUG ALERT
            isRecording = true;
            speakBtn.classList.add('recording');
            speakBtn.querySelector('.speak-btn-label').textContent = 'Stop';
            timerEl.classList.add('visible');
            recordingSeconds = 0;
            updateTimer();
            recordingTimer = setInterval(() => {
                recordingSeconds++;
                updateTimer();
            }, 1000);
        };

        recognition.onresult = (event) => {
            let interimTranscript = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                if (event.results[i].isFinal) {
                    finalTranscript += event.results[i][0].transcript + ' ';
                } else {
                    interimTranscript += event.results[i][0].transcript;
                }
            }
        };

        recognition.onerror = (event) => {
            alert("SPEECH ERROR: " + event.error); // DEBUG ALERT
            if (event.error === 'not-allowed') {
                alert("Please enable microphone permissions in Settings!");
            }
        };

        recognition.onend = () => {
            if (isRecording) {
                // If it stopped but we didn't want it to, restart (Android does this sometimes)
                try { recognition.start(); } catch (e) {}
                return;
            }
            clearInterval(recordingTimer);
            speakBtn.classList.remove('recording');
            speakBtn.querySelector('.speak-btn-label').textContent = 'Speak';
            timerEl.classList.remove('visible');
            
            const text = finalTranscript.trim();
            if (text) {
                alert("Captured: " + text); // DEBUG ALERT
                currentCapture.text = text;
                showPostRecordFlow();
            } else {
                alert("No speech detected.");
            }
            finalTranscript = '';
        };

        // BUTTON CLICK HANDLER
        speakBtn.addEventListener('click', () => {
            alert("Button Clicked!"); // DEBUG ALERT
            
            if (isRecording) {
                isRecording = false;
                recognition.stop();
            } else {
                finalTranscript = '';
                recognition.lang = settings.defaultLang;
                try {
                    recognition.start();
                } catch (e) {
                    alert("START ERROR: " + e.message);
                }
            }
        });

    } catch (err) {
        alert("SETUP ERROR: " + err.message);
    }
}

function updateTimer() {
    const m = Math.floor(recordingSeconds / 60);
    const s = recordingSeconds % 60;
    timerEl.textContent = m + ':' + String(s).padStart(2, '0');
}

// --- REST OF YOUR UI LOGIC (Simplified for brevity, keep your original UI functions below) ---
// Note: I am not including the UI rendering logic here to save space, 
// but you MUST keep your existing showScreen, renderCaptures, etc. functions.
// Just make sure 'showPostRecordFlow' is defined!

function showPostRecordFlow() {
    // Simple version to prove it works
    const saved = confirm("Save this thought?\n\n" + currentCapture.text);
    if (saved) {
        captures.unshift({
            id: Date.now().toString(),
            text: currentCapture.text,
            createdAt: new Date().toISOString()
        });
        localStorage.setItem(STORAGE_KEY, JSON.stringify(captures));
        alert("Saved!");
    }
}

// Service Worker Registration
if ('serviceWorker' in navigator) {
    navigator.serviceWorker.register('sw.js').then(function(registration) {
        console.log('ServiceWorker registration successful with scope: ', registration.scope);
    }, function(err) {
        console.log('ServiceWorker registration failed: ', err);
    });
}
</script>
